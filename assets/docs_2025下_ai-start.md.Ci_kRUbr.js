import{_ as i,c as r,o as t,a2 as a}from"./chunks/framework.CriqKoQt.js";const d=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"docs/2025下/ai-start.md","filePath":"docs/2025下/ai-start.md","lastUpdated":1768538822000}'),l={name:"docs/2025下/ai-start.md"};function o(w,e,b,s,n,c){return t(),r("div",null,e[0]||(e[0]=[a('<ol><li><p>管中窥豹，定性理解： 1）《这就是ChatGPT》，微信读书有，可以自己看。 2）《面向没做过算法的程序员的大模型核心概念讲解》<a href="https://doc.weixin.qq.com/doc/w3_ACIASwbdAFwIBCiHZr3TwSBURdg9s" target="_blank" rel="noreferrer">https://doc.weixin.qq.com/doc/w3_ACIASwbdAFwIBCiHZr3TwSBURdg9s</a> ，可能需要讲，只是自己看，有难懂的地方。 3）后台接触LLM推理，可以以 <a href="https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices" target="_blank" rel="noreferrer">https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices</a> 为线索，了解里面提到的概念、设备。选择性深入算法、开源实现、CUDA并行计算等领域继续了解。</p></li><li><p>对细节和底层掌握不全，但是完全定型理解，细节也有较好的把握： 《动手学深度学习》电子版，<a href="https://zh.d2l.ai/" target="_blank" rel="noreferrer">https://zh.d2l.ai/</a> ，微信读书上也有。 对关键细节，建议深入了解清楚，非关键概念，记住是这么回事儿就行。关键概念，可以看如下视频： 1）十分钟搞定最大似然估计 <a href="https://www.bilibili.com/video/BV1Hb4y1m7rE" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV1Hb4y1m7rE</a> 2）【概率论】贝叶斯公式与后验概率 <a href="https://www.bilibili.com/video/BV1mY411h7ps" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV1mY411h7ps</a> 3）极大似然估计/最大后验估计—通过抛硬币例子理解 <a href="https://www.bilibili.com/video/BV1GZ4y1m7gv" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV1GZ4y1m7gv</a> 4）「一个模型」教你搞定贝叶斯和全概率公式 <a href="https://www.bilibili.com/video/BV1a4411B7B4" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV1a4411B7B4</a> 5）“损失函数”是如何设计出来的？直观理解“最小二乘法”和“极大似然估计法” <a href="https://www.bilibili.com/video/BV1Y64y1Q7hi/" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV1Y64y1Q7hi/</a> 6）“交叉熵”如何做损失函数？打包理解“信息量”、“比特”、“熵”、“KL散度”、“交叉熵” <a href="https://www.bilibili.com/video/BV15V411W7VB" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV15V411W7VB</a> 7）重新理解线性回归 - 2 - 广义线性模型：sigmoid函数到底是怎么来的 <a href="https://www.bilibili.com/video/BV13X4y1R7im" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV13X4y1R7im</a></p></li><li><p>能得到一个比较扎实的基础。耗时比较长，学习难度曲线比较平滑： <a href="https://www.bilibili.com/video/BV1JE411w7Ub" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV1JE411w7Ub</a> 吴恩达&lt;斯坦福 CS229 机器学习&gt;课程 <a href="https://www.bilibili.com/video/BV1SL411U7SF" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV1SL411U7SF</a> &lt;斯坦福 CS224n 自然语言处理&gt;课程 <a href="https://www.bilibili.com/video/BV12341167kL" target="_blank" rel="noreferrer">https://www.bilibili.com/video/BV12341167kL</a> &lt;伯克利 CS285 | 深度强化学习&gt;课程</p></li><li><p>全面的纯理论讲解，学习曲线极其陡峭。默认读者精通微积分、概率论（经典概率与贝叶斯概率）， 了解过拓扑学等数学学科。可以看得半懂不懂，增加见识的读物： 深度学习第二人Bengio写的书《深度学习》微信读书上就有,<a href="https://book.douban.com/subject/27087503/" target="_blank" rel="noreferrer">https://book.douban.com/subject/27087503/</a></p></li></ol>',1)]))}const h=i(l,[["render",o]]);export{d as __pageData,h as default};
